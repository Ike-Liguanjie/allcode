
1.go基础相关
1. Slice切片和数组的区别（高频）
    1.长度：切片是不定长度，可以随着数据增多而扩容。数组是固定长度，无法扩容。
    2.赋值：切片是类型引用，内存地址不发生改变。数组是拷贝一个全新数组，内存地址发生改变。
    3.传参：切片作为参数传递，在函数内改变会影响到上层。数组作为参数传递如果不传指针，则无法影响到原参数。
    注意点1：切片因为是引用，在使用一个极大数组的小切片时，会导致原数组内存不释放，引起内存泄露，正确做法是拷贝一个新切片出来，释放原数组内存。
    注意点2：切片扩容规则是：当新容量比原有容量的2倍还大，那将直接扩容到新容量。当长度小于1024，每次扩容为原来的2倍，大于的时候扩容原来的1.25倍。
    注意点3：切片不具备线程安全，如果在多线程操作切片的时候需要使用sync.Mutex互斥锁或者channel管道来控制。
2. 如何避免panic
    panic会导致程序异常退出，recover方法可以捕获panic错误，使用defer关键字可以保证程序在发生panic错误的时候运行recover方法
    多层defer是后进先出，最后进入的异常最先报，然后一层层上报，每一层错误码记录清晰，通过日志定位问题所在
3. goroutine详解
    go语言中的协程，可以通过go关键字起一个goroutine来运行方法（这里引申出进程、线程、协程的定义）
    需要注意的是，go语言中main方法本身就是一个主goroutine，其他所有的协程都是子goroutine，main方法结束后，其他所有子goroutine都会一起结束。
    goroutine可以通过runtime.Gosched()主动交出控制器，来运行其他goroutine。
    这里讲到go中goroutine的调度策略，即GMP模型。
4. channel详解  》缓冲区
    定义：通俗的理解，channel是一个特定类型的管道，不同的goroutine可以通过这个管道进行数据传递。
    管道遵循先进先出的原则，通过->箭头操作符来进行存取，在channel为空时候读取会被block，满了存放会被block。
    当channel被关闭的时候，无法再继续往channel中发送数据，但是可以接收。
    通过select可以处理对通道的发送和接收。(select case 可以理解为switch)

5. Gc算法（三色标记法）（超高频）
    golangGC的历程：V1.3使用标记-清除(Mark-Sweep)，V1.5开始三色标记法，V1.8是三色标记法+混合屏障
    golangv1.5版本之后开始使用的三色标记法，在这之前使用的是标记-清除(Mark-Sweep)
    缺点：不支持并发，操作过程中需要暂停程序，暂停时间较长

    三色标记法：
    1.从根对象出发，将当前可达对象标记为灰色
    2.遍历灰色对象，将当前可达对象标记为灰色，自身标记为黑色
    3.重复步骤2
    4.清除所有白色对象
    缺点：会出现错标和漏标的情况，因为在并发情况下，垃圾回收线程和业务逻辑一起运行，在本来标记为灰色的对象遗弃，会导致这种浮动垃圾存活到下一次GC。
    漏标是本来应该在下一轮扫描的灰色对象被标记为黑色，导致下一轮未遍历该灰色对象，将其子对象给回收。

    插入写屏障：在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)，注意栈上不启用插入屏障
    缺点：扫描结束后需要对栈上rescan，耗费时间。
    删除写屏障：被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。
    缺点：回收精度低，会导致本应该清除的垃圾存活到下一次GC。

    用来降低STW的混合写屏障：
    1.GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)，
    2.GC期间，任何在栈上创建的新对象，均为黑色。
    3.被删除的对象标记为灰色。
    4.被添加的对象标记为灰色。

6. GMP模型（超高频！！！）
    Goroutine (G) 是 Go 语言中轻量级的并发执行单元，类似于线程但比线程更小、更灵活。每个 goroutine 都有自己独立的堆栈和寄存器等信息，可以通过 go 关键字创建并发执行任务。
    操作系统线程（M）是实际的执行单元，负责将 goroutine 调度到逻辑处理器上执行。Go 程序中通常会创建多个 M，以便在多核 CPU 上实现并发执行。
    逻辑处理器（P）是一个虚拟的执行单元，负责调度 goroutine 和执行 Go 代码。Go 程序中有多个 P，每个 P 可以运行多个 goroutine，因此可以实现真正的并发执行。

    G是goroutine，golang中的协程，包含当前执行的M指针和sched相关寄存器地址。内存决定数量
    M是machine，golang中的线程，包含g0和tls本地线程池，g0负责G调度切换，线程池储存了当前运行的G。默认10000
    P是process，golang中的调度器，包含G队列，G头和G尾以及队列长度。数量由CPU的核数来决定
    M通过P来运行G，因为P的存在，M无需绑定和记录G的状态，每个G必须绑定在P上才可以执行，P相当于是G的CPU，P给M提供内存分配和可执行G的信息。
    P的调度策略：主动调度、被动调度、正常调度和抢占调度。
        主动调度：用户通过执行runtime.Gosched让当前G让出执行权，进入队列等待下次执行。
        被动调度：G被阻塞导致无法调度，底层会走进gopark方法，最终通过其他G执行goready来恢复阻塞，将G重新放入队列中等待下次执行。
        正常调度：G正常结束运行并死亡，继续执行下一个G。
        抢占调度：全局G monitor会轮询监控所有P，当前G执行时间过久且P资源紧张的时候会解除这个G与P的绑定关系，让其他G来执行，同时将G重新放入队列中等待下次执行。
    P如何寻找可执行的G：
        G分为两个队列，全局队列和P的本地队列。P执行的时候优先寻找本地队列，本地队列为空就去全局队列拉取。
        当全局队列也为空的时候就去网络轮询器network poller(golang的I/O调度模型)中寻找。
        前面条件都不满足的时候就会触发work stealing，即从其他P的本地队列中获取一半G来减缓其他P的压力。
        注意：P每调度执行61次G，都会去执行一个全局队列中的G，并拉取一个全局队列的G到本地队列中。若当前本地队列已满，则会返还一半的G到全局队列里。
    P如何执行G：
        1.更新G的状态信息
        2.绑定G与M的关系
        3.更新P的调度次数
        4.调用gogo方法，从g0切换到g并执行，执行完毕后调用m_call切换为g0

7. Map并发安全
    同slice一样，Map的并发操作也是不安全的，可以通过sync.Mutex互斥锁或者sync.Map来实现并发安全。
    map是引用类型
    map遍历是无序的
    map是非线程安全的
    map的哈希冲突解决方式是链表法
    map的扩容不是一定会新增空间，也有可能是只是做了内存整理
    map的迁移是逐步进行的，在每次赋值时，会做至少一次迁移工作
    map中删除key，有可能导致出现很多空的kv，这会导致迁移操作，如果可以避免，尽量避免
8. profile工具
    profile工具是来检测程序性能的，自带的有net/http/pprof
    我没用过这些

2.mysql相关
1. select Sql语句的执行过程
    1.客户端与服务端建立连接，通过TCP
    2.查询缓存，如果命中直接返回结果。(8.0版本删除了查询缓存这一步)
    3.解析器解析SQL语句，查询是否存在语法错误。
    4.执行SQL语句，优化器对语句进行优化处理，比如选择哪一种索引，优化条件命中联合索引等。
    5.上述步骤都是在server层，执行器执行sql语句通过调用引擎存储层的API来提取数据，返回给客户端。
2. mysql默认存储引擎，区别（InnoDB，MyISAM）
    InnoDB是mysql的默认引擎(5版本以后)，采用MVCC作为版本控制，同时实现了4个隔离级别，默认的隔离级别是可重复读。
    InnDB的主键索引是簇族索引，采用B+树结构，且实现了行锁来保证并发。
    Myisam不支持事务和行锁，导致崩溃后无法恢复数据。

3. 索引数据结构，聚簇索引和非聚簇索引介绍，B+树跟B树相比的优点（超高频）
4. 默认的隔离级别，一共有哪些，解决了什么问题
    默认的隔离级别是可重复读。隔离级别一共4个，分别是读未提交、读已提交、可重复读和串行化。
    分别解决了脏读、不可重复读和幻读。
5. 事务的特性
    1、原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。
        也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。
　　 2、一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。
　　 3、隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。
　　 4、持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。
6. MVCC
    Mutil-Version Concurrency Control，MySQL的多版本并发控制，InnoDB引擎下的。
    每个聚簇索引下会有额外两个隐藏字段，trx_id和roll_pointer。
    trx_id记录了更新操作的事务ID，roll_pointer记录了undo log的地址指针。
    每个事务会创建一个read view，里面有4个字段。
    creator_trx_id：创建当前Read View所对应的事务ID
    m_ids：所有当前未提交事务的事务ID，也就是活跃事务的事务id列表
    min_trx_id：m_ids里最小的事务id值
    max_trx_id：InnoDB 需要分配给下一个事务的事务ID值（事务 ID 是累计递增分配的，所以后面分配的事务ID一定会比前面的大！）
    每次读取会去比较trx_id与creator_trx_id的大小，小于自己就直接读，大于自己就去历史的undo log里去读。
7. ACID
    就是事务的4个特性原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability），通过MVCC来保证的。
8. explain中索引的类型
    * consts：单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。
    * ref：使用普通的索引
    * range：对索引进行范围检索
    * Index：索引物理文件全扫，速度非常慢。
9. 什么是最左匹配原则和联合索引
    由多个字段建立的索引就叫做联合索引或多列索引
    最左前缀匹配原则顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。
    最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配
    比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。
    =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。

3.Redis相关
1. 基础数据类型
    1.动态字符串SDS
    2.链表
    3.字典
    4.跳跃表
    5.整数集合
    6.压缩列表
2. 跳跃表的实现
    本质上还是链表，只不过在链表的基础上增加了层的概念。
    skiplist4个成员，header头结点、tail尾结点、level层级和length元素个数。
    每个节点都包含L1、L2...层级，层级包含指向下一个同层元素的指针和跨度，每个节点包含BW指针，指向上一个元素。
    Score存储了该节点的value值，obj包含了当前节点的成员对象。
    新节点的level根据幂次定律随机生成，新节点插入满足链表插入。
3. 缓存穿透、缓存击穿、缓存雪崩都是什么，怎么预防
    缓存穿透：请求的数据在缓存和数据库当中都没有，这样请求会不断落在数据库上，仿佛缓存不存在一样，并发高了容易把数据库打死。
    解决办法一是对请求过来的数据做校验防止恶意攻击，二是数据库不存在的数据也会给一个表示没有数据的缓存，设置一个过期时间，过期了才再次请求。判断数据是否存在可以用布隆过滤器

    缓存击穿：某个访问量较大的热点数据过期，请求直接打到数据库上，导致数据库直接被打死。
    解决办法是对于热点数据设置永不过期。

    缓存雪崩：大量的key在某个时间点刚好同时过期，这时候所有的请求都直接打在了数据库上，导致数据库被打死。
    解决办法是在批量添加key的时候设置随机过期时间，避免同一时间大量的key一起失效。
4. 单线程还是多线程（6.0版本开始支持多线程处理I/O读写操作）》单线程为什么这么快（内存上操作、key/value的数据结构、I/O多路复用、单线程避免了线程切换开销）
5. 集群模式  高可用
    通过一主多从的多节点服务，主从复制、哨兵模式、切片集群。
    主从复制：在从服务器通过replicaof ip port 命令来成为目标服务器的从服务器
    第一次主从复制过程如下：
        1.B服务器执行replicaof ip port
        2.B服务器向A服务器发送psync runID offset 命令，此时第一次连接不知道A服务器的runID和offset，所以是psync ? -1
        3.A服务器向B服务器发送FULLRESYNC runID offset，B服务器收到并记录参数
        4.A服务器通过bgsave生成RDB文件，传输给B服务器，生成过程中的写操作存储到缓冲区
        5.B服务器收到RDB文件，抛弃当前所有数据，载入传输过来的RDB文件
        6.A服务器向B服务器发送缓冲区的写操作，B服务器执行，完成数据同步。
    建立连接之后，主从服务器之间会维护一个TCP长连接，后续主服务器的写操作会同步到从服务器，完成数据同步。
    注意：从服务器也可以设置自己的从服务器，降低主服务器的同步压力。
    增量同步：当建立第一次连接之后，后续主从服务器之间出现网络中断的时候导致同步不及时，在恢复连接的时候进行的操作。
    在缓冲区repl_backlog_buffer中会记录replication offset，主从服务器通过offset来判断需要增量同步多少数据。
    如果slave_repl_offset已经不在缓冲区内，则进行全量复制，传输RDB文件。
    所以应该设置适当的缓冲区大小，来减少全量复制的开销。

    哨兵模式：观察者节点，来观察主节点状态，当主节点发生异常的时候及时选举一个从节点切换为主节点。
    完整的主节点异常，切换从节点为主节点的步骤分为一下几步：
    观察：哨兵节点每隔1秒ping主节点，主节点收到后会响应哨兵节点。
    判断：主节点没有及时回复哨兵节点的ping命令，则会被该哨兵节点判断为主观下线，此时该哨兵节点会发起投票，进入下一步。
        为了避免因为网络拥堵等原因造成哨兵节点误判，所以哨兵节点一般会设置多个。
        当上一步某个哨兵节点发起投票后，所有哨兵节点会根据自己的情况判断主节点是否异常。
        当判断为异常的总票数大于设置的quorum，此时客观认为主节点异常，主节点为客观下线，进入下一步。
    选举：这里的选举是指选举出执行主从切换的哨兵节点。
        谁在上一步发起了投票，那么该哨兵节点就是候选者，当候选者获得大于半数哨兵节点的票的时候，该哨兵节点成为哨兵leader，负责下一步的主从切换。
    主从切换：在异常的主节点下属从节点中选取一个，作为新的主节点。
        选取规则：首先通过dow-after-millisecond * 10这个配置项的超时时间，当断连超过10次即视为网络不好，排除该部分节点。
                剩下的节点经过优先级、复制数据大小、ID大小的三轮比较，最终选取一个出来作为主节点。
                优先级：slave-priority 配置项可以设置节点优先级，数字越小优先级越高。
                数据量：子节点同步的数据offset，同步进度高的优先考虑。
                节点ID：子节点的runID，数字小的优先考虑。
        通过上面的选举规则，来选举一个新的子节点成为主节点。此时哨兵leader向从节点发送SLAVEOF no one，解除其从节点身份，更换为主节点。
        此时哨兵leader给原主节点下的其他从节点发送SLAVEOF ip port命令来让子节点指向新的主节点，同时监控下线的主节点，在主节点重新上线的时候将其变为子节点指向新的主节点。
    通知：通知客户端主节点地址有变更。
        通过redis的发布与订阅来实现（+switch-master频道），当主节点发生变化的时候，哨兵会发布新的主节点地址，此时客户端会收到该地址并与新的主节点地址进行通信。

    此时整个哨兵模式的主节点切换过程就完成了。（哨兵节点之间的互相发现也是通过发布订阅来实现的，__sentinel__:hello频道）


6. 事务
    同mysql事务不一样，redis事务会将整个事务中的命令全部执行才会去执行别的命令，而mysql事务会在执行错误后回滚所有操作，redis并不能。
7. 发布与订阅
    客户端订阅某个频道的时候，redis在进行某些特定操作就会在该频道发布消息，订阅的客户端就可以在这个频道获取，例如主节点切换。
8. 数据持久化
    redis提供两种数据持久化，RDB和AOF
    RDB，快照方式将内存数据持久化到硬盘。save同步阻塞进行保存，bgsave异步fork子进程出来进行保存。(默认方式)
    AOF，命令方式将每次的写命令储存起来，文件过大时可以用rewriteaof进行文件重写。always永远同步写操作，everysec每秒异步操作一次。

    比较：RDB快照文件比AOF要小，恢复数据速度快。但在持久化期间写入的数据RDB不会保存，如果出现问题会丢失这部分数据。
        AOF文件写入性能高，且数据最多丢失1秒。

    混合持久化：结合了RDB和AOF的方式，文件前半部分是RDB文件，恢复快，后半部分是APF文件，数据丢失少。
9.过期策略和内存淘汰策略
    过期策略采用惰性删除+定期清理
        惰性删除：访问key的时候检测是否过期，如果过期则删除key并返回null
        定期清理：随机选取20个key进行检测，过期超过1/4则继续重复该步骤，直到超过25ms或者不满足条件位置。
    内存淘汰
        volatile设置了过期时间的
            random随机淘汰任意
            lru淘汰最长时间未使用的
            lfu淘汰最少使用的
            ttl淘汰过期时间最短的
        allkeys所有数据范围
            random随机淘汰任意
            lru淘汰最长时间未使用的
            lfu淘汰最少使用的

4.k8s、docker相关
1. 基础概念，有哪些组件，起什么作用
    基础概念：K8S是一个容器管理平台，可以自动化实现负载均衡，弹性伸缩等功能。
    主要组件：
        API Server：
            所有服务访问的入口，它提供了 Kubernetes 集群中各个组件之间的通信和管理接口，所有操作都需要通过 API Server 发起和处理。
            当用户使用 kubectl 命令或者其他 Kubernetes 客户端工具时，实际上是通过 API Server 和集群进行交互的。
        Controller Manager：
            负责监控和维护集群中所有资源对象的状态，以及进行自动化控制和管理操作。Controller Manager 中包含多个控制器，
            每个控制器负责监控和维护一种资源对象的状态，如 Deployment、ReplicaSet、DaemonSet 等，
            同时根据用户的需求，自动进行相应的容器调度、扩容、缩容等操作，他们是处理集群中常规任务的后台线程。
        Scheduler：
            主要负责根据集群中各个节点的负载情况，以及用户的调度策略，将新创建的 Pod 分配到合适的节点上。
            Scheduler 会根据 Pod 的资源需求、节点的资源情况、节点之间的网络距离等因素进行智能调度，从而实现负载均衡和资源最大化利用的目标。
        Etcd：
            分布式键值存储系统，用于保存集群中的所有状态信息和元数据。所有与 Kubernetes 集群相关的信息，
            包括 Pod、Service、Deployment 等对象的创建、更新和删除等操作，都将被记录在 Etcd 中。
            这样可以使得 Kubernetes 系统具有高可用性和复原能力，并且允许多个 Master 节点之间进行数据同步和共享。

2. 如何监听pod状态，pod内容器是否相互隔离
3. Docker与虚拟机的区别

5.网络相关
1. Tcp的三次握手，四次挥手
    名词解释：
        SYN、ACK、FIN，TCP协议报文的标志位。
        seq：Sequence Numbe 序列号
        ack：Acknowledgement Number 确认号
    三次挥手：
        1.客户端发送SYN=1，seq为x的包，同时自身进入SYN_SEND状态。
        2.服务端收到客户端的包后，返回SYN=1，ACK=1，seq=y，ack=x+1的包，同时自身进入SYN_RCVD状态。
        3.客户端收到后返回SYN=0，ACK=1，ack=y+1的包，此时进入ESTABLISHED状态，服务端收到后也进入ESTABLISHED状态，此时三次握手结束，TCP连接建立。
    四次挥手：
        1.客户端发送FIN=1，seq为x的包给服务端，表明自身没有数据可发送了，同时自身进入FIN_WAIT_1状态。
        2.服务端收到后返回ACK=1，ack=x+1的包给客户端，表示已收到请求并在后续准备断开连接，此时服务端进入CLOSE_WAIT状态，客户端在收到这个确认包后会进入FIN_WAIT_2状态。
        3.服务端准备好断开连接，此时发送FIN=1，ack=y的包给客户端请求断开连接，然后自身进入LAST_ACK状态，等待客户端最后一个ack确认包。
        4.客户端收到后，返回ACK=1，ack=y+1的确认包给服务端，同时自身进入TIME_AWAIT状态，等待接收可能出现的重传ACK包。
            此时服务端收到后会进入CLOSED状态关闭连接，客户端在等待2MSL后没收到服务端的ACK包就认为服务端已正常关闭，此时客户端也进入CLOSED状态，四次挥手结束。
2. Tcp与Udp的区别

3. time_await和time_close，大量出现怎么解决
4. http和http2的区别，http3了解么
5. Https的加密、证书相关
6. Websocket详解》稳定性、兼容性

6.操作系统相关
1. 协程与线程的区别
2. 查看端口命令  lsof -i:8888或者netstat -tunlp
3. 查看资源命令 top
4. I/O多路复用
5. 悲观锁、乐观锁，应用场景简单说下

7.ES相关
1. 倒排索引
2. 怎么保证数据一致性
3. 如何降低压力
4. 日志存储时长是多少

8.算法相关
1. 基础数据结构复习：数组、链表、哈希表、树
2. LRU算法（超高频！！！）
3. 两个有序列表合成一个有序列表（双指针）（高频）
4. 括号匹配
5. 实现有序map（带左右节点的哈希表）
6. 反转单链表
7. 快排
8. 寻找第K大元素（最大堆）
9. 二分查找（有序才可二分）
10. 限流算法
11. 二叉树（前序、中序、后序） PS：我的弱项，需要加强
    * 给前序、中序推后序和给中序、后序推前序
    * 翻转二叉树
    * 二叉树是否是完全二叉树
    * 二叉树是否对称
12.顺时针旋转矩阵


9.杂项
1. 读扩散和写扩散
2. 不要用共享内存来通信，而是用通信来共享内存（单机都可以，分布式要利用中间件来通信共享）channel也是遵循这个原则
3. Nginx负载均衡
4. 浏览器键入地址后到加载内容一共发生了什么
5. 日志工具（可作为拓展，目前用的是kibana）
6. go与node的区别
